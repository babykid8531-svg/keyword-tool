import streamlit as st
from pytrends.request import TrendReq
import pandas as pd
import math
import time

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(
    page_title="í‚¤ì›Œë“œ ì¶”ì²œ ë° ë¶„ì„ë°›ê¸°",
    layout="wide"
)

st.title("í‚¤ì›Œë“œ ì¶”ì²œ ë° ë¶„ì„ë°›ê¸°")
st.caption("ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” ğŸ˜Š")

# =========================
# session_state ì´ˆê¸°í™”
# =========================
if "analyzed" not in st.session_state:
    st.session_state.analyzed = False
if "all_keywords" not in st.session_state:
    st.session_state.all_keywords = []
if "raw_df" not in st.session_state:
    st.session_state.raw_df = pd.DataFrame()
if "final_candidates" not in st.session_state:
    st.session_state.final_candidates = []
if "selected_keywords" not in st.session_state:
    st.session_state.selected_keywords = []

# =========================
# í‚¤ì›Œë“œ ì…ë ¥
# =========================
keyword = st.text_input(
    "ë¶„ì„ í‚¤ì›Œë“œ",
    placeholder="ì˜ˆ: ì „ì£¼ ë•ì§„ê³µì›"
)

# =========================
# í‚¤ì›Œë“œ í™•ì¥ í•¨ìˆ˜
# =========================
def expand_keywords(keyword):
    base = keyword.replace(" ", "")
    variants = set()

    variants.add(keyword)
    variants.add(base)

    suffixes = [
        "ì—°ê½ƒ", "ì—°ê½ƒ ì‹œì¦Œ", "ì‹œì¦Œ", "ëª…ì†Œ",
        "ì‚¬ì§„", "ë°©ë¬¸", "ê°œí™”ì‹œê¸°"
    ]

    for s in suffixes:
        variants.add(f"{keyword} {s}")

    parts = keyword.split()
    if len(parts) >= 2:
        place = parts[-1]
        variants.add(place)
        for s in suffixes:
            variants.add(f"{place} {s}")

    return list(variants)

# =========================
# Google Trends ë¶„ì„
# =========================
@st.cache_data(show_spinner=False)
def analyze(keyword):
    pytrends = TrendReq(hl="ko", tz=540)
    expanded = expand_keywords(keyword)

    frames = []

    for kw in expanded:
        try:
            pytrends.build_payload([kw], timeframe="today 12-m", geo="KR")
            related = pytrends.related_queries()

            if kw not in related or related[kw] is None:
                continue

            rq = related[kw]
            if rq.get("top") is not None:
                frames.append(rq["top"])
            if rq.get("rising") is not None:
                frames.append(rq["rising"])

            if frames:
                break
        except Exception:
            continue

    if not frames:
        return [], pd.DataFrame()

    df = pd.concat(frames, ignore_index=True)
    df = df.drop_duplicates(subset="query").head(50)

    df["ê²€ìƒ‰ëŸ‰"] = "ì¤‘"
    df.loc[:2, "ê²€ìƒ‰ëŸ‰"] = "ë†’ìŒ"
    df.loc[3:6, "ê²€ìƒ‰ëŸ‰"] = "ì¤‘ìƒ"
    df["ì´ìœ "] = "ì—°ê´€ í™•ì¥ ê²€ìƒ‰ ê¸°ë°˜ ì •ë³´í˜• í‚¤ì›Œë“œ"

    return df["query"].tolist(), df

# =========================
# SEO + AI ê²€ìƒ‰ìš© ìë™ ì„ ë³„
# =========================
def auto_select_keywords(df):
    banned = ["í›„ê¸°", "íë§", "ì¶”ì²œ", "ê°•ì¶”", "ê°ì„±"]
    result = []

    for kw in df["query"]:
        if any(b in kw for b in banned):
            continue
        if len(kw) < 3:
            continue
        if " " not in kw:
            continue
        result.append(kw)

    return result[:10]

# =========================
# ë¶„ì„ ì‹¤í–‰
# =========================
if st.button("í‚¤ì›Œë“œ ì¶”ì²œ ë° ë¶„ì„í•˜ê¸°"):
    if not keyword:
        st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    with st.spinner("Google Trends ê¸°ë°˜ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        time.sleep(1)
        all_kw, df = analyze(keyword)

    if not all_kw:
        st.info("ì—°ê´€ í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()

    st.session_state.analyzed = True
    st.session_state.all_keywords = all_kw
    st.session_state.raw_df = df
    st.session_state.final_candidates = auto_select_keywords(df)
    st.session_state.selected_keywords = []

# =========================
# ê²°ê³¼ ì¶œë ¥
# =========================
if st.session_state.analyzed:

    # 1ï¸âƒ£ ì—°ê´€ í‚¤ì›Œë“œ 50ê°œ
    st.markdown("## 1ï¸âƒ£ ì—°ê´€ í‚¤ì›Œë“œ 50ê°œ")
    cols = 5
    rows = math.ceil(len(st.session_state.all_keywords) / cols)
    grid = [
        st.session_state.all_keywords[i * cols:(i + 1) * cols]
        for i in range(rows)
    ]
    st.dataframe(pd.DataFrame(grid).fillna(""))

    # 2ï¸âƒ£ ìƒìœ„ ë…¸ì¶œ ê°€ëŠ¥ í‚¤ì›Œë“œ
    st.markdown("## 2ï¸âƒ£ ìƒìœ„ ë…¸ì¶œ ê°€ëŠ¥ì„± ë†’ì€ í‚¤ì›Œë“œ")
    st.dataframe(
        st.session_state.raw_df[["query", "ê²€ìƒ‰ëŸ‰", "ì´ìœ "]]
        .rename(columns={"query": "í‚¤ì›Œë“œ"})
        .head(10),
        use_container_width=True
    )

    # 3ï¸âƒ£ ìë™ ì„ ë³„ í‚¤ì›Œë“œ ì„ íƒ
    st.markdown("## 3ï¸âƒ£ ê¸€ ìƒì„±ìš© í‚¤ì›Œë“œ ì„ íƒ (ìµœëŒ€ 3ê°œ)")
    st.caption("SEO Â· ìƒìœ„ë…¸ì¶œ Â· AI ê²€ìƒ‰ ê¸°ì¤€ ìë™ ì„ ë³„")

    for kw in st.session_state.final_candidates:
        checked = st.checkbox(
            kw,
            key=f"kw_{kw}",
            value=kw in st.session_state.selected_keywords
        )
        if checked and kw not in st.session_state.selected_keywords:
            if len(st.session_state.selected_keywords) < 3:
                st.session_state.selected_keywords.append(kw)
        elif not checked and kw in st.session_state.selected_keywords:
            st.session_state.selected_keywords.remove(kw)

    # =========================
    # ê¸€ ë¼ˆëŒ€ ìƒì„±
    # =========================
    if st.button("âœ… ì„ íƒí•œ í‚¤ì›Œë“œë¡œ ê¸€ ë¼ˆëŒ€ ë§Œë“¤ê¸°"):
        if len(st.session_state.selected_keywords) != 3:
            st.error("í‚¤ì›Œë“œë¥¼ ì •í™•íˆ 3ê°œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            k1, k2, k3 = st.session_state.selected_keywords

            st.markdown("## âœï¸ ì§€ì¹¨ì„œ ê¸°ë°˜ ê¸€ ë¼ˆëŒ€")

            st.markdown(f"""
### ì œëª©  
{k1} {k2} {k3} ì´ì •ë¦¬

### ë„ì…ë¶€  
ì•ˆë…•í•˜ì„¸ìš”.  
ì˜¤ëŠ˜ì€ {k1}ì—ì„œ í•œ ë²ˆì¯¤ ê¶ê¸ˆí•´ì§ˆ ë§Œí•œ {k2}ë¥¼ ì •ë¦¬í•´ë´¤ìŠµë‹ˆë‹¤.  
ì´ ê³µê°„ì˜ ì„±ê²©ê³¼ ì´ìš© ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.  
ìš´ì˜ì‹œê°„, ì´ìš© ë°©ë²•, ì£¼ì°¨ì™€ ë™ì„ ê¹Œì§€ í•œ ë²ˆì— í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì²˜ìŒ ë°©ë¬¸í•˜ì‹œëŠ” ë¶„ì´ë¼ë©´ ëê¹Œì§€ ë³´ì‹œë©´ ë„ì›€ì´ ë©ë‹ˆë‹¤.

### â‘  ì´ ê³µê°„ì€ ë¬´ì—‡ì¸ê°€ìš”  
{k2}ëŠ” {k1}ì— ìœ„ì¹˜í•œ ì¥ì†Œë¡œ, íŠ¹ì • ëª©ì ì„ ìœ„í•´ ì¡°ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.  
ê³¼ê±° ìš©ë„ì™€ ì¡°ì„± ë°°ê²½ì„ ê±°ì³ í˜„ì¬ëŠ” ë°©ë¬¸í˜• ê³µê°„ìœ¼ë¡œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.

### â‘¡ ì–¸ì œÂ·ì–´ë–»ê²Œ ì´ìš©í•˜ë‚˜ìš”  
ìš´ì˜ ìš”ì¼ê³¼ ì‹œê°„ì€ ì •í•´ì ¸ ìˆìœ¼ë©° ì¼ë¶€ ê¸°ê°„ì€ ë³€ë™ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì…ì¥ ë§ˆê° ì‹œê°„ê³¼ íœ´ë¬´ì¼ì€ ì‚¬ì „ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.  
â€» ë°©ë¬¸ ì „ ê³µì‹ ì•ˆë‚´ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

### â‘¢ ë‚´ë¶€ êµ¬ì„±Â·ì´ìš© íë¦„ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”  
ì…ì¥ì€ ì£¼ ì¶œì…êµ¬ ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.  
ì´ìš© ë™ì„ ì€ í•œ ë°©í–¥ íë¦„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©° í‰ê·  ì†Œìš” ì‹œê°„ì€ ì •í•´ì ¸ ìˆìŠµë‹ˆë‹¤.  
ğŸ“Œ í˜¼ì¡ ì‹œê°„ëŒ€ë¥¼ í”¼í•˜ë©´ ë™ì„  ì´ë™ì´ ìˆ˜ì›”í•©ë‹ˆë‹¤.

### â‘£ ì ‘ê·¼ ë°©ë²•Â·ì£¼ì°¨Â·êµí†µì€ ì–´ë–¤ê°€ìš”  
ì£¼ì°¨ëŠ” ìœ ë£Œ ë˜ëŠ” ë¬´ë£Œë¡œ ìš´ì˜ë˜ë©° ê³µê°„ ìˆ˜ëŠ” ì œí•œì ì…ë‹ˆë‹¤.  
ëŒ€ì¤‘êµí†µ ì´ìš© ì‹œ ì£¼ìš” ì •ë¥˜ì¥ì—ì„œ í•˜ì°¨ í›„ ë„ë³´ ì´ë™ì´ í•„ìš”í•©ë‹ˆë‹¤.  
ì ‘ê·¼ì„±ì€ ëª©ì ì— ë”°ë¼ ì²´ê° ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.

### â‘¤ ì´ëŸ° ì‚¬ëŒì—ê²Œ ì˜ ë§ì•„ìš”  
- ì •ë³´ ìœ„ì£¼ë¡œ ì°¨ë¶„íˆ ë‘˜ëŸ¬ë³´ê³  ì‹¶ì€ ë¶„  
- ì²˜ìŒ ë°©ë¬¸í•´ ë™ì„  ì•ˆë‚´ê°€ í•„ìš”í•œ ë¶„  
- ì‹œê°„ ê³„íšì„ ì„¸ì›Œ ë°©ë¬¸í•˜ë ¤ëŠ” ë¶„  
ë‹¨, ì¦‰í¥ì ì¸ ë°©ë¬¸ì—ëŠ” ì œì•½ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë§ˆë¬´ë¦¬  
{k2}ëŠ” ì‚¬ì „ì— ì •ë³´ë¥¼ ì•Œê³  ë°©ë¬¸í•˜ë©´ ì´ìš© íš¨ìœ¨ì´ ë†’ì€ ê³µê°„ì…ë‹ˆë‹¤.  
ìš´ì˜ ì‹œê°„ê³¼ ì ‘ê·¼ ë°©ë²•ë§Œ ì •ë¦¬í•´ë„ ë°©ë¬¸ íë¦„ì´ í›¨ì”¬ ì•ˆì •ë©ë‹ˆë‹¤.  
ë°©ë¬¸ ì „ì— ì´ ì •ë¦¬ ë‚´ìš©ì„ ì°¸ê³ í•´ë³´ì‹œê² ì–´ìš”?

### í•´ì‹œíƒœê·¸  
#{k2} #{k1} #{k1}ê°€ë³¼ë§Œí•œê³³ #{k3} #{ì´ìš©ì•ˆë‚´} #{ì£¼ì°¨ì •ë³´}
""")
