import streamlit as st
import pandas as pd
from pytrends.request import TrendReq
from openai import OpenAI
import time

# =====================
# ê¸°ë³¸ ì„¤ì •
# =====================
st.set_page_config(page_title="í‚¤ì›Œë“œ ì¶”ì²œ ë° ë¶„ì„ë°›ê¸°", layout="wide")
st.title("í‚¤ì›Œë“œ ì¶”ì²œ ë° ë¶„ì„ë°›ê¸°")
st.caption("Google Trends ê¸°ë°˜ Â· ë„¤ì´ë²„ SEO ì‹¤ì „ìš©")

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# =====================
# Session State
# =====================
for k in ["df", "top10", "post", "generating"]:
    if k not in st.session_state:
        st.session_state[k] = None

# =====================
# Google Trends
# =====================
@st.cache_data(ttl=3600)
def get_trend_score(keyword):
    try:
        pytrends = TrendReq(hl="ko", tz=540)
        pytrends.build_payload([keyword], timeframe="today 12-m", geo="KR")
        data = pytrends.interest_over_time()
        if data.empty:
            return 0
        return int(data[keyword].mean())
    except:
        return 0

# =====================
# í‚¤ì›Œë“œ ë¶„ì„
# =====================
def analyze_keywords(base):
    suffixes = [
        "ì£¼ì°¨","ìœ„ì¹˜","ê°€ëŠ”ë²•","ìš´ì˜ì‹œê°„","ì‚°ì±…",
        "ì‚¬ì§„ ëª…ì†Œ","ë°ì´íŠ¸","ê°€ë³¼ë§Œí•œê³³","í›„ê¸°",
        "ì½”ìŠ¤","ì•¼ê²½","í˜¼ì¡ë„","ê³„ì ˆ","ë‚ ì”¨",
        "ì£¼ë³€ ë§›ì§‘","ê·¼ì²˜ ì¹´í˜","ì•„ì´ì™€","í˜¼ì",
        "ì£¼ë§","í‰ì¼","ì…ì¥ë£Œ","ì§€ë„"
    ]

    rows = []
    for s in suffixes:
        kw = f"{base} {s}"
        trend = get_trend_score(kw)
        seo = 40 if s in ["ì£¼ì°¨","ìœ„ì¹˜","ê°€ëŠ”ë²•","ìš´ì˜ì‹œê°„"] else 20
        click = 30 if s in ["ì‚¬ì§„ ëª…ì†Œ","ë°ì´íŠ¸","ê°€ë³¼ë§Œí•œê³³","í›„ê¸°"] else 10
        ai = 20 if len(kw) >= 10 else 10

        score = trend*0.4 + seo*0.3 + click*0.2 + ai*0.1

        rows.append({
            "í‚¤ì›Œë“œ": kw,
            "SEO ì ìˆ˜": int(score)
        })
        time.sleep(0.15)

    df = pd.DataFrame(rows).sort_values("SEO ì ìˆ˜", ascending=False)
    return df, df.head(10)["í‚¤ì›Œë“œ"].tolist()

# =====================
# UI
# =====================
base_kw = st.text_input("ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì „ì£¼ ë•ì§„ê³µì›")

if st.button("í‚¤ì›Œë“œ ë¶„ì„"):
    with st.spinner("í‚¤ì›Œë“œ ë¶„ì„ ì¤‘..."):
        df, top10 = analyze_keywords(base_kw)
        st.session_state.df = df
        st.session_state.top10 = top10
        st.session_state.post = None

# 1ï¸âƒ£ í‚¤ì›Œë“œ í‘œ (ì‘ê²Œ)
if st.session_state.df is not None:
    st.subheader("1ï¸âƒ£ ì—°ê´€ í‚¤ì›Œë“œ 50ê°œ")
    st.dataframe(
        st.session_state.df.head(50),
        height=180,
        use_container_width=True,
        hide_index=True
    )

# 2ï¸âƒ£ ìµœì  í‚¤ì›Œë“œ 10ê°œ
if st.session_state.top10:
    st.subheader("2ï¸âƒ£ SEOÂ·í´ë¦­Â·AI ìµœì  í‚¤ì›Œë“œ 10ê°œ")
    for i, kw in enumerate(st.session_state.top10, 1):
        st.write(f"{i}. {kw}")

    # ğŸ”’ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
    if st.button("ì´ í‚¤ì›Œë“œë¡œ ê¸€ ìƒì„±", disabled=st.session_state.generating):
        st.session_state.generating = True
        with st.spinner("ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€ ìƒì„± ì¤‘..."):
            prompt = f"""
ë„ˆëŠ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ SEO ì „ë¬¸ ì‘ê°€ë‹¤.

ì£¼ì œ: {base_kw}
í•µì‹¬ í‚¤ì›Œë“œ:
- {st.session_state.top10[0]}
- {st.session_state.top10[1]}
- {st.session_state.top10[2]}

ì¡°ê±´:
- ì •ë³´ ì¤‘ì‹¬
- ì²˜ìŒ ë°©ë¬¸ì ê¸°ì¤€
- ê³¼ì¥ ê¸ˆì§€
- ì œëª© â†’ ë„ì… â†’ ì†Œì œëª© 5ê°œ â†’ ë§ˆë¬´ë¦¬
"""

            res = client.responses.create(
                model="gpt-4.1-mini",
                input=prompt,
                max_output_tokens=900
            )

            st.session_state.post = res.output_text
        st.session_state.generating = False

# 3ï¸âƒ£ ìƒì„± ê²°ê³¼
if st.session_state.post:
    st.markdown("## âœï¸ ìƒì„±ëœ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€")
    st.markdown(st.session_state.post)
